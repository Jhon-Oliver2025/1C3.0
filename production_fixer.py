#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Corretor de Produ√ß√£o - 1Crypten
Corrige automaticamente os problemas identificados na valida√ß√£o
Prepara o sistema para deploy em produ√ß√£o
"""

import os
import json
import shutil
from pathlib import Path
from datetime import datetime

class ProductionFixer:
    """Corretor autom√°tico para problemas de produ√ß√£o"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.fixes_applied = []
        
    def run_fixes(self):
        """Executa todas as corre√ß√µes necess√°rias"""
        print("üîß CORRETOR DE PRODU√á√ÉO - 1CRYPTEN")
        print("="*80)
        
        print("\nüì¶ Corrigindo package.json...")
        self.fix_package_json()
        
        print("\nüê≥ Corrigindo Docker Compose...")
        self.fix_docker_compose()
        
        print("\nüîí Melhorando .gitignore...")
        self.fix_gitignore()
        
        print("\n‚ö° Otimizando configura√ß√µes...")
        self.optimize_configs()
        
        print("\nüìã Criando scripts de deploy...")
        self.create_deploy_scripts()
        
        self.print_summary()
    
    def fix_package_json(self):
        """Corrige package.json do frontend"""
        package_json_path = self.project_root / 'front' / 'package.json'
        
        if not package_json_path.exists():
            print("   ‚ö†Ô∏è package.json n√£o encontrado")
            return
        
        try:
            with open(package_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Adicionar scripts essenciais
            if 'scripts' not in data:
                data['scripts'] = {}
            
            scripts_to_add = {
                'start': 'vite preview --host 0.0.0.0 --port 3000',
                'build': 'vite build',
                'build:prod': 'vite build --mode production',
                'preview': 'vite preview',
                'preview:prod': 'vite preview --mode production --host 0.0.0.0',
                'lint': 'eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0',
                'type-check': 'tsc --noEmit'
            }
            
            added_scripts = []
            for script_name, script_command in scripts_to_add.items():
                if script_name not in data['scripts']:
                    data['scripts'][script_name] = script_command
                    added_scripts.append(script_name)
            
            # Salvar package.json atualizado
            with open(package_json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            if added_scripts:
                self.fixes_applied.append(f"‚úÖ Scripts adicionados ao package.json: {', '.join(added_scripts)}")
                print(f"   ‚úÖ Scripts adicionados: {', '.join(added_scripts)}")
            else:
                print("   ‚úÖ package.json j√° est√° correto")
                
        except Exception as e:
            print(f"   ‚ùå Erro ao corrigir package.json: {e}")
    
    def fix_docker_compose(self):
        """Corrige docker-compose.production.yml"""
        docker_compose_path = self.project_root / 'docker-compose.production.yml'
        
        # Criar docker-compose.production.yml se n√£o existir
        if not docker_compose_path.exists():
            docker_compose_content = '''version: '3.8'

services:
  app:
    build:
      context: ./back
      dockerfile: Dockerfile
    container_name: 1crypten-backend
    restart: unless-stopped
    environment:
      - FLASK_ENV=production
      - PYTHONPATH=/app
    env_file:
      - .env.production
    ports:
      - "5000:5000"
    volumes:
      - ./back:/app
      - /app/__pycache__
    networks:
      - 1crypten-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    build:
      context: ./front
      dockerfile: Dockerfile
    container_name: 1crypten-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
    networks:
      - 1crypten-network
    depends_on:
      - app

  nginx:
    image: nginx:alpine
    container_name: 1crypten-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    networks:
      - 1crypten-network
    depends_on:
      - app
      - frontend

networks:
  1crypten-network:
    driver: bridge

volumes:
  postgres_data:
'''
            
            with open(docker_compose_path, 'w', encoding='utf-8') as f:
                f.write(docker_compose_content)
            
            self.fixes_applied.append("‚úÖ docker-compose.production.yml criado")
            print("   ‚úÖ docker-compose.production.yml criado")
        else:
            print("   ‚úÖ docker-compose.production.yml j√° existe")
        
        # Criar Dockerfile para o frontend se n√£o existir
        frontend_dockerfile = self.project_root / 'front' / 'Dockerfile'
        if not frontend_dockerfile.exists():
            dockerfile_content = '''# Build stage
FROM node:18-alpine as build

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy source code
COPY . .

# Build application
RUN npm run build:prod

# Production stage
FROM node:18-alpine as production

WORKDIR /app

# Install serve globally
RUN npm install -g serve

# Copy built application
COPY --from=build /app/dist ./dist

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/ || exit 1

# Start application
CMD ["serve", "-s", "dist", "-l", "3000"]
'''
            
            with open(frontend_dockerfile, 'w', encoding='utf-8') as f:
                f.write(dockerfile_content)
            
            self.fixes_applied.append("‚úÖ Dockerfile do frontend criado")
            print("   ‚úÖ Dockerfile do frontend criado")
    
    def fix_gitignore(self):
        """Melhora o .gitignore"""
        gitignore_path = self.project_root / '.gitignore'
        
        # Conte√∫do completo do .gitignore
        gitignore_content = '''# Dependencies
node_modules/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
PIPFILE.lock

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
.env.production
.env.n8n
.venv
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Coverage directory used by tools like istanbul
coverage/
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage
.grunt

# Bower dependency directory
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons
build/Release

# Dependency directories
jspm_packages/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# parcel-bundler cache
.cache
.parcel-cache

# Next.js build output
.next

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
public

# Storybook build outputs
.out
.storybook-out

# Temporary folders
tmp/
temp/

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Backup files
*.backup
*.old
*.temp
*.bak

# Database
*.db
*.sqlite
*.sqlite3

# Certificates
*.pem
*.key
*.crt
*.p12
*.pfx

# Docker
.dockerignore

# Build outputs
build/
dist/
out/

# Cache
.cache/
.parcel-cache/
.next/
.nuxt/

# Diagnostic reports
system_diagnostic_report.json
production_validation_report.json
optimization_backup/
optimization_log.txt

# Test files
test_*.py
*_test.py
debug_*.py
diagnose*.py
check_*.py

# HTML debug files
*.html
!index.html
!public/*.html

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# pipenv
Pipfile.lock

# PEP 582
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/
'''
        
        with open(gitignore_path, 'w', encoding='utf-8') as f:
            f.write(gitignore_content)
        
        self.fixes_applied.append("‚úÖ .gitignore atualizado com padr√µes de seguran√ßa")
        print("   ‚úÖ .gitignore atualizado")
    
    def optimize_configs(self):
        """Otimiza configura√ß√µes para produ√ß√£o"""
        # Criar .env.production.template se n√£o existir
        env_template_path = self.project_root / '.env.production.template'
        if not env_template_path.exists():
            env_template_content = '''# Configura√ß√µes de Produ√ß√£o - 1Crypten
# Copie este arquivo para .env.production e configure as vari√°veis

# Flask
FLASK_ENV=production
FLASK_DEBUG=False
SECRET_KEY=your-super-secret-key-here

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-anon-key
SUPABASE_SERVICE_KEY=your-supabase-service-key

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/1crypten

# API Keys
BINANCE_API_KEY=your-binance-api-key
BINANCE_SECRET_KEY=your-binance-secret-key

# Telegram
TELEGRAM_BOT_TOKEN=your-telegram-bot-token
TELEGRAM_CHAT_ID=your-telegram-chat-id

# Mercado Pago
MERCADO_PAGO_ACCESS_TOKEN=your-mercado-pago-token
MERCADO_PAGO_PUBLIC_KEY=your-mercado-pago-public-key

# Email
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# Security
JWT_SECRET_KEY=your-jwt-secret-key
CORS_ORIGINS=https://yourdomain.com

# Performance
WORKERS=4
THREADS=2
TIMEOUT=120

# Monitoring
LOG_LEVEL=INFO
SENTRY_DSN=your-sentry-dsn
'''
            
            with open(env_template_path, 'w', encoding='utf-8') as f:
                f.write(env_template_content)
            
            self.fixes_applied.append("‚úÖ Template de produ√ß√£o .env criado")
            print("   ‚úÖ .env.production.template criado")
        
        # Criar configura√ß√£o nginx para produ√ß√£o
        nginx_dir = self.project_root / 'nginx'
        nginx_dir.mkdir(exist_ok=True)
        
        nginx_prod_config = nginx_dir / 'nginx.prod.conf'
        if not nginx_prod_config.exists():
            nginx_content = '''events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    
    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;
    
    # Performance
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;
    
    # Upstream backend
    upstream backend {
        server app:5000;
    }
    
    # Upstream frontend
    upstream frontend {
        server frontend:3000;
    }
    
    server {
        listen 80;
        server_name _;
        
        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https:; media-src 'self'; object-src 'none'; child-src 'none'; frame-ancestors 'self'; form-action 'self'; base-uri 'self';" always;
        
        # API routes
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeouts
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }
        
        # Login rate limiting
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;
            
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # Frontend routes
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Handle client-side routing
            try_files $uri $uri/ /index.html;
        }
        
        # Static files caching
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            proxy_pass http://frontend;
        }
        
        # Health check
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
'''
            
            with open(nginx_prod_config, 'w', encoding='utf-8') as f:
                f.write(nginx_content)
            
            self.fixes_applied.append("‚úÖ Configura√ß√£o Nginx para produ√ß√£o criada")
            print("   ‚úÖ nginx.prod.conf criado")
    
    def create_deploy_scripts(self):
        """Cria scripts de deploy automatizado"""
        scripts_dir = self.project_root / 'scripts'
        scripts_dir.mkdir(exist_ok=True)
        
        # Script de deploy
        deploy_script = scripts_dir / 'deploy.sh'
        deploy_content = '''#!/bin/bash

# Script de Deploy - 1Crypten
# Executa deploy completo em produ√ß√£o

set -e  # Parar em caso de erro

echo "üöÄ Iniciando deploy do 1Crypten..."

# Verificar se est√° na branch main
if [ "$(git branch --show-current)" != "main" ]; then
    echo "‚ùå Deploy deve ser feito a partir da branch main"
    exit 1
fi

# Verificar se h√° mudan√ßas n√£o commitadas
if [ -n "$(git status --porcelain)" ]; then
    echo "‚ùå H√° mudan√ßas n√£o commitadas. Commit antes do deploy."
    exit 1
fi

# Pull das √∫ltimas mudan√ßas
echo "üì• Atualizando c√≥digo..."
git pull origin main

# Verificar se .env.production existe
if [ ! -f ".env.production" ]; then
    echo "‚ùå Arquivo .env.production n√£o encontrado"
    echo "üí° Copie .env.production.template e configure as vari√°veis"
    exit 1
fi

# Parar containers existentes
echo "üõë Parando containers..."
docker-compose -f docker-compose.production.yml down

# Build das imagens
echo "üî® Construindo imagens..."
docker-compose -f docker-compose.production.yml build --no-cache

# Iniciar servi√ßos
echo "üöÄ Iniciando servi√ßos..."
docker-compose -f docker-compose.production.yml up -d

# Aguardar servi√ßos ficarem prontos
echo "‚è≥ Aguardando servi√ßos..."
sleep 30

# Verificar sa√∫de dos servi√ßos
echo "üè• Verificando sa√∫de dos servi√ßos..."
if curl -f http://localhost/health > /dev/null 2>&1; then
    echo "‚úÖ Deploy conclu√≠do com sucesso!"
    echo "üåê Aplica√ß√£o dispon√≠vel em: http://localhost"
else
    echo "‚ùå Falha no health check"
    echo "üìã Verificar logs: docker-compose -f docker-compose.production.yml logs"
    exit 1
fi

echo "üéâ Deploy finalizado!"
'''
        
        with open(deploy_script, 'w', encoding='utf-8') as f:
            f.write(deploy_content)
        
        # Tornar execut√°vel (no Linux/Mac)
        try:
            os.chmod(deploy_script, 0o755)
        except:
            pass
        
        # Script de rollback
        rollback_script = scripts_dir / 'rollback.sh'
        rollback_content = '''#!/bin/bash

# Script de Rollback - 1Crypten
# Reverte para vers√£o anterior

set -e

echo "üîÑ Iniciando rollback..."

# Verificar se h√° commit anterior
if [ -z "$1" ]; then
    echo "‚ùå Especifique o commit para rollback: ./rollback.sh <commit-hash>"
    exit 1
fi

COMMIT_HASH=$1

# Verificar se o commit existe
if ! git cat-file -e "$COMMIT_HASH" 2>/dev/null; then
    echo "‚ùå Commit $COMMIT_HASH n√£o encontrado"
    exit 1
fi

# Fazer checkout do commit
echo "üì• Revertendo para commit $COMMIT_HASH..."
git checkout "$COMMIT_HASH"

# Rebuild e restart
echo "üî® Reconstruindo aplica√ß√£o..."
docker-compose -f docker-compose.production.yml down
docker-compose -f docker-compose.production.yml build --no-cache
docker-compose -f docker-compose.production.yml up -d

# Verificar sa√∫de
sleep 30
if curl -f http://localhost/health > /dev/null 2>&1; then
    echo "‚úÖ Rollback conclu√≠do com sucesso!"
else
    echo "‚ùå Falha no rollback"
    exit 1
fi

echo "üéâ Rollback finalizado!"
'''
        
        with open(rollback_script, 'w', encoding='utf-8') as f:
            f.write(rollback_content)
        
        try:
            os.chmod(rollback_script, 0o755)
        except:
            pass
        
        self.fixes_applied.append("‚úÖ Scripts de deploy criados")
        print("   ‚úÖ Scripts de deploy e rollback criados")
    
    def print_summary(self):
        """Imprime resumo das corre√ß√µes"""
        print("\n" + "="*80)
        print("üìä RESUMO DAS CORRE√á√ïES APLICADAS")
        print("="*80)
        
        print(f"\n‚úÖ Total de corre√ß√µes aplicadas: {len(self.fixes_applied)}")
        
        for fix in self.fixes_applied:
            print(f"   {fix}")
        
        print(f"\nüéØ Pr√≥ximos passos:")
        print(f"   1. Configure o arquivo .env.production")
        print(f"   2. Execute: python production_validator.py")
        print(f"   3. Se tudo estiver OK, execute: ./scripts/deploy.sh")
        print(f"   4. Monitore os logs: docker-compose logs -f")
        
        print(f"\nüìÅ Arquivos importantes criados:")
        print(f"   üìÑ .env.production.template")
        print(f"   üê≥ docker-compose.production.yml")
        print(f"   üåê nginx/nginx.prod.conf")
        print(f"   üöÄ scripts/deploy.sh")
        print(f"   üîÑ scripts/rollback.sh")
        
        print(f"\nüéâ Sistema corrigido e pronto para valida√ß√£o!")

def main():
    """Fun√ß√£o principal"""
    project_root = os.getcwd()
    
    print("üîß CORRETOR DE PRODU√á√ÉO 1CRYPTEN")
    print(f"üìÅ Projeto: {project_root}")
    print(f"‚è∞ Iniciado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    # Executar corre√ß√µes
    fixer = ProductionFixer(project_root)
    fixer.run_fixes()

if __name__ == '__main__':
    main()